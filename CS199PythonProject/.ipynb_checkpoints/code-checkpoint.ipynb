{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Modules...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name cbook",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-29c688a98b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m from matplotlib.cbook import (\n\u001b[1;32m    128\u001b[0m     _backports, mplDeprecation, dedent, get_label, sanitize_sequence)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name cbook"
     ]
    }
   ],
   "source": [
    "print(\"Importing Modules...\")\n",
    "\n",
    "# importing the necessary modules\n",
    "import os\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring twitter API...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Configuring twitter API...\")\n",
    "\n",
    "# to use the Twitter API\n",
    "api_key= 'h4PFqa8plinWSJABvdzELmUMH'\n",
    "api_secret= 'LHEVK0N9Qg2QJ1iSw4dbZGnkfN6iompYnoOB987BshfBmiDifR'\n",
    "access_token= '1203973257541693440-JLqAVav815FFOde3CtgsIP0WIbCq4N'\n",
    "access_token_secret= 'xWCDX5UJsuHJiJq8Do04cAQSTBJtf5tA34oTs4aa76qbL'\n",
    "\n",
    "auth = tw.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data...\")\n",
    "\n",
    "# general 2020 election\n",
    "search0 = '#2020election -filter:retweets' # searches twitter for #2020election tags and filters retweets\n",
    "search1 = '#election2020 -filter:retweets' # searches twitter for #election2020 tags and filters retweets\n",
    "\n",
    "# specific candidates\n",
    "search2 = '#yang2020 -filter:retweets'\n",
    "search3 = '#bernie2020 -filter:retweets'\n",
    "search4 = '#warren2020 -filter:retweets'\n",
    "search5 = '#biden2020 -filter:retweets'\n",
    "search6 = '#pete2020 -filter:retweets'\n",
    "search7 = '#tulsi2020 -filter:retweets'\n",
    "search8 = '#klobuchar2020 -filter:retweets'\n",
    "search9 = '#steyer2020 -filter:retweets'\n",
    "search10 = '#cory2020 -filter:retweets'\n",
    "search11 = '#castro2020 -filter:retweets'\n",
    "search12 = '#marianne2020 -filter:retweets'\n",
    "search13 = '#bennet2020 -filter:retweets'\n",
    "search14 = '#delaney2020 -filter:retweets'\n",
    "search15 = '#bloomberg2020 -filter:retweets'\n",
    "search16 = '#patrick2020 -filter:retweets'\n",
    "search17 = '#trump2020 -filter:retweets'\n",
    "\n",
    "\n",
    "# a sample of tweets that include the #2020election tag\n",
    "tweets_sample0 = tw.Cursor(api.search, q=search0, lang=\"en\", tweet_mode='extended').items(2000)\n",
    "\n",
    "# a sample of tweets that include the #election2020 tag\n",
    "tweets_sample1 = tw.Cursor(api.search, q=search1, lang=\"en\", tweet_mode='extended').items(2000)\n",
    "\n",
    "# a sample of tweets that include the #yang2020 tag\n",
    "tweets_sample2 = tw.Cursor(api.search, q=search2, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #bernie2020 tag\n",
    "tweets_sample3 = tw.Cursor(api.search, q=search3, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #warren2020 tag\n",
    "tweets_sample4 = tw.Cursor(api.search, q=search4, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #biden2020 tag\n",
    "tweets_sample5 = tw.Cursor(api.search, q=search5, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #pete2020 tag\n",
    "tweets_sample6 = tw.Cursor(api.search, q=search6, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #tulsi2020 tag\n",
    "tweets_sample7 = tw.Cursor(api.search, q=search7, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #klobuchar2020 tag\n",
    "tweets_sample8 = tw.Cursor(api.search, q=search8, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #steyer2020 tag\n",
    "tweets_sample9 = tw.Cursor(api.search, q=search9, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #cory2020 tag\n",
    "tweets_sample10 = tw.Cursor(api.search, q=search10, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #castro2020 tag\n",
    "tweets_sample11 = tw.Cursor(api.search, q=search11, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #marianne2020 tag\n",
    "tweets_sample12 = tw.Cursor(api.search, q=search12, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #bennet2020 tag\n",
    "tweets_sample13 = tw.Cursor(api.search, q=search13, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #delaney2020 tag\n",
    "tweets_sample14 = tw.Cursor(api.search, q=search14, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #bloomberg2020 tag\n",
    "tweets_sample15 = tw.Cursor(api.search, q=search15, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #patrick2020 tag\n",
    "tweets_sample16 = tw.Cursor(api.search, q=search16, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "# a sample of tweets that include the #trump2020 tag\n",
    "tweets_sample17 = tw.Cursor(api.search, q=search17, lang=\"en\", tweet_mode='extended').items(1000)\n",
    "\n",
    "\n",
    "# data structures, records username, location, and text \n",
    "users = []\n",
    "locs = []\n",
    "text = []\n",
    "\n",
    "usersfile = open(\"users.txt\",\"r\")\n",
    "for user in usersfile:\n",
    "    users.append(user.replace(\"\\n\",''))\n",
    "usersfile.close()\n",
    "\n",
    "locsfile = open(\"locs.txt\", \"r\")\n",
    "for loc in locsfile:\n",
    "    locs.append(loc.replace(\"\\n\",''))\n",
    "locsfile.close()\n",
    "\n",
    "textfile = open(\"text.txt\", \"r\")\n",
    "for field in textfile:\n",
    "    text.append(field.replace(\"\\n\",''))\n",
    "textfile.close()\n",
    "    \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-f0ea671d6bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets_sample0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tweepy/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tweepy/cursor.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tweepy/binder.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep for few extra sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for tweet in tweets_sample0:\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 0...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 0...\")\n",
    "\n",
    "for tweet in tweets_sample0:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # writing to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # writing to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 1...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 1...\")\n",
    "\n",
    "for tweet in tweets_sample1:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # writing to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # writing to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 2...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 2...\")\n",
    "\n",
    "for tweet in tweets_sample2:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 3...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 3...\")\n",
    "\n",
    "for tweet in tweets_sample3:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 4...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 4...\")\n",
    "\n",
    "for tweet in tweets_sample4:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n', ' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 5...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 5...\")\n",
    "\n",
    "for tweet in tweets_sample5:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 6...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 6...\")\n",
    "\n",
    "for tweet in tweets_sample6:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 7...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 7...\")\n",
    "\n",
    "for tweet in tweets_sample7:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 8...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 8...\")\n",
    "\n",
    "for tweet in tweets_sample8:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 9...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 9...\")\n",
    "\n",
    "for tweet in tweets_sample9:\n",
    "    if(tweet.user.screen_name.replace('\\n','') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 10...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 10...\")\n",
    "\n",
    "for tweet in tweets_sample10:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 11...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 11...\")\n",
    "\n",
    "for tweet in tweets_sample11:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 12...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 12...\")\n",
    "\n",
    "for tweet in tweets_sample12:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 13...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 13...\")\n",
    "\n",
    "for tweet in tweets_sample13:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 14...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 14...\")\n",
    "\n",
    "for tweet in tweets_sample14:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 15...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 15...\")\n",
    "\n",
    "for tweet in tweets_sample15:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 16...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 16...\")\n",
    "\n",
    "for tweet in tweets_sample16:\n",
    "    if(tweet.user.screen_name.replace('\\n',' ') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording data from sample 17...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording data from sample 17...\")\n",
    "\n",
    "for tweet in tweets_sample17:\n",
    "    if(tweet.user.screen_name.replace('\\n','') not in users):\n",
    "        # write to data structures\n",
    "        users.append(tweet.user.screen_name.replace('\\n',' '))\n",
    "        locs.append(tweet.user.location.replace('\\n',' '))\n",
    "        text.append(tweet.full_text.replace('\\n',' '))\n",
    "        \n",
    "        # write to files\n",
    "        usersfile = codecs.open(\"./users.txt\",\"a\",\"utf-8\")\n",
    "        usersfile.write(tweet.user.screen_name.replace('\\n',' ')+\"\\n\")\n",
    "        usersfile.close()\n",
    "        locsfile = codecs.open(\"./locs.txt\",\"a\",\"utf-8\")\n",
    "        locsfile.write(tweet.user.location.replace('\\n',' ')+\"\\n\")\n",
    "        locsfile.close()\n",
    "        textfile = codecs.open(\"./text.txt\",\"a\",\"utf-8\")\n",
    "        textfile.write(tweet.full_text.replace('\\n',' ')+\"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7989"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# records the screen name, location and text of the tweet\n",
    "users_locs_msg = []\n",
    "\n",
    "for i in range(len(users)):\n",
    "    users_locs_msg.append([users[i], locs[i], text[i]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dictionary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:20: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Making dictionary...\")\n",
    "\n",
    "# making a dictionary for all the tags in the dataset\n",
    "tagsDict = {}\n",
    "\n",
    "# okay characters\n",
    "okay_characters = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t',\n",
    "                   'u','v','w','x','y','z','#','0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "# declare newTag and flag\n",
    "newTag = ''\n",
    "recordTag = 0\n",
    "\n",
    "# for loop to iterate over all text in all tweets\n",
    "for user in users_locs_msg:\n",
    "    for letter in user[2]:\n",
    "        # if the letter is not a number of letter or #, then we have finished iterating over a new tag\n",
    "        if(letter.lower() not in okay_characters and recordTag == 1 and newTag != '#'):\n",
    "            recordTag = 0\n",
    "            if(newTag in tagsDict.keys()):\n",
    "                tagsDict[newTag] = tagsDict[newTag] + 1\n",
    "            else:\n",
    "                tagsDict[newTag] = 1\n",
    "        # if record tag is 1, then we add a new letter to the new tag\n",
    "        if(recordTag):\n",
    "            newTag = newTag + letter.lower()\n",
    "        # if the letter is # then we have started a new tag\n",
    "        if(letter == '#'):\n",
    "            newTag = '#'\n",
    "            recordTag = 1\n",
    "        \n",
    "# tagsDict now records all tags found in the tweets   \n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5711</th>\n",
       "      <td>#2020election</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>#election2020</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>#trump2020</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>#bernie2020</td>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>#yang2020</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>#warren2020</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>#bloomberg2020</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>#biden2020</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>#yanggang</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>#tulsi2020</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>#pete2020</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>#maga</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>#marianne2020</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>#democrats</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>#trump</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>#cory2020</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>#kag</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>#castro2020</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>#notmeus</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>#peteforamerica</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>#joebiden</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>#klobuchar2020</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>#humanityfirst</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>#teampete</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>#impeachment</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>#peteforpresident</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>#petebuttigieg</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>#biden</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>#impeachmenthearings</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>#politics</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>#medicareforall</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>#berniesanders</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>#wwg1wga</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>#kag2020</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>#andrewyang</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>#tulsigabbard</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>#bloomberg</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>#potus</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>#wintheera</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>#impeachmenthoax</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>#usa</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>#impeachinghearing</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>#qanon</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>#vote</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>#mariannewilliamson</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>#impeachmenthearing</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>#freedomdividend</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>#elizabethwarren</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>#walkaway</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>#republicans</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>#draintheswamp</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>#yangmediablackout</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>#feelthebern</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>#voteblue</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>#tulsiforpresident</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>#gop</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>#democrat</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>#teamwarren</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>#ukraine</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>#dnc</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>#berniebeatstrump</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>#yanggang2020</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>#kamalaharris</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>#fakenews</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>#yangganglove</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>#donaldtrump</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>#america</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>#demdebate</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>#impeachtrump</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>#americafirst</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>#mayorpete</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>#cnn</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>#nomiddleground</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>#resist</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>#maga2020</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#iacaucus</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>#ubi</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>#dems</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>#nhpolitics</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>#fitn</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>#corybooker</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5613</th>\n",
       "      <td>#buttigieg</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>#greennewdeal</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>#math</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>#election</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>#warren</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>#impeachdonaldtrumpnow</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>#sanders2020</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>#trump2020landslidevictory</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>#foxnews</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>#iowa</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>#bernieblackout</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047</th>\n",
       "      <td>#impeachmentinquiry</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>#bernie</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>#hunterbiden</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>#bidenpushupchallenge</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>#igreport</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>#voteblue2020</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>#democraticdebate</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>#impeachandremovetrump</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>#trump2020landslide</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>#marianneforpresident</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>#2020elections</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>#buttigieg2020</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>#nomalarkey</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>#amyklobuchar</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>#wethepeople</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>#pelosi</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>#kamala2020</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>#impeachmentday</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>#mondaythoughts</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>#bigtruth</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>#resistance</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>#china</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>#russia</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>#bidencrimefamily</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>#democraticparty</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>#q</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>#corruption</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>#amyforamerica</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>#m4a</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#news</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>#thegreatawakening</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>#trumprally</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>#berniesanders2020</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>#trumpisalaughingstock</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>#votebluenomatterwho</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>#nancypelosi</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>#yang</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>#trumpimpeachment</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>#bluewave2020</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>#tcot</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>#bidencorruption</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>#womenforyang</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>#botsontheground</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>#advertising</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>#trumppencemustgo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>#pete2020https</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>#endcorporategreed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>#hindsight2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>#impeachtrumpnobody</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>#election2020maybe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>#moscowmuppets</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>#joeiscomingthis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>#charitablegiving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>#ifb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>#wetherealpatriotsofamerica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>#trusttheplancross</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>#genius</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>#trumppyromaniac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>#bernie2020red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>#infinity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>#tee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>#tulsi2020no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>#makeithappen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>#lettulsispeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>#opinionpolls</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>#warren2020neither</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>#donkeyshit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>#dcdp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>#bernie2020msnbc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>#un</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>#warrensanders</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>#moscowmitchtraitor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>#kamalaharrisforthepeople</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>#resistmust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>#rainbowsix</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>#ladiesnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>#crowdpacthat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>#littlemichael</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>#maxinewatersgiven</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>#studio10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>#andrewyang2020this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>#wintheeranow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>#mikehesson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>#taxrevenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>#countdown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>#scholars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>#magacrazytrainxpress</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>#fakeoutrageso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>#newwavepatriotism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>#onechance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>#firststepact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>#election2020new</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>#savedemocracy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2565</th>\n",
       "      <td>#yangonsteam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>#freechelsea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>#relatablememes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>#obamalegacy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>#election2020politics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>#dailypoll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>#woman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>#berndowntheestablishment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>#baitandswitchliz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>#yang2020ok</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>#politicslivewhat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>#abuseofcongresspower</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>#psychologists4marianne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>#lit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>#populism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>#prints</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>#bloombergadssuck</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>#bettemidler</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>#artsed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>#nomoreneoliberalstrue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>#youdontknowpete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>#trumpbyalandslide</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>#dreamticket</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2681</th>\n",
       "      <td>#policiesoneverything</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>#restoredemocracyhappening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>#usfca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>#trumpism</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>#maltese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>#sweetbeadz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>#merica</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>#belonging</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>#bernie2020america</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>#creepjoebiden</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>#19dec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>#farmersfirst</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>#goldman</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>#mariannewilliamson2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>#downsyndrome</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>#wisconsinforbernie</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>#gillum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>#sextoy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>#warren2020hell</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>#trumpclaus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>#he</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>#corporate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>#teachersforwarren</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>#smearcampaign</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>#bernie2020hillary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>#neveragainisnow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>#therealjoebiden</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>#metalcomedyftw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>#vote4yang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>#kag2020andrew</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>#democratshateisrael</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>#hufflepuff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>#homeland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>#twitterbuzz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>#huntersgreenroom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>#mediabuzz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>#electmorewomen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>#warren2020misogyny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>#protestants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>#tom2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>#castro2020our</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>#judiciarycommittee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>#pete2020really</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>#yanggangpass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>#4thindustrialrevolution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>#nsu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>#yanggangloveit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>#popcorntime</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>#yang2020here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>#leave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>#trumprallysunrise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>#fanniegate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>#justiceforbrianterry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>#pentagon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>#oromo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>#mikebloombergwhat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>#fightthefakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>#biden2020agreed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>#uglywifebaby</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>#warren2020agree</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6091 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Tag  Frequency\n",
       "5711  #2020election                1222     \n",
       "3564  #election2020                1041     \n",
       "679   #trump2020                   877      \n",
       "4571  #bernie2020                  752      \n",
       "3017  #yang2020                    584      \n",
       "1976  #warren2020                  556      \n",
       "2928  #bloomberg2020               524      \n",
       "856   #biden2020                   507      \n",
       "1225  #yanggang                    445      \n",
       "448   #tulsi2020                   350      \n",
       "2912  #pete2020                    330      \n",
       "743   #maga                        249      \n",
       "2275  #marianne2020                205      \n",
       "3324  #democrats                   204      \n",
       "570   #trump                       202      \n",
       "5341  #cory2020                    184      \n",
       "1894  #kag                         161      \n",
       "4767  #castro2020                  142      \n",
       "5762  #notmeus                     132      \n",
       "4921  #peteforamerica              99       \n",
       "3989  #joebiden                    95       \n",
       "2823  #klobuchar2020               87       \n",
       "1145  #humanityfirst               85       \n",
       "1408  #teampete                    83       \n",
       "3875  #impeachment                 80       \n",
       "1418  #peteforpresident            79       \n",
       "2905  #petebuttigieg               79       \n",
       "5795  #biden                       78       \n",
       "3506  #impeachmenthearings         67       \n",
       "4699  #politics                    66       \n",
       "1705  #medicareforall              66       \n",
       "5534  #berniesanders               65       \n",
       "917   #wwg1wga                     65       \n",
       "3733  #kag2020                     60       \n",
       "3741  #andrewyang                  56       \n",
       "1156  #tulsigabbard                55       \n",
       "1904  #bloomberg                   53       \n",
       "3407  #potus                       51       \n",
       "5137  #wintheera                   51       \n",
       "5175  #impeachmenthoax             49       \n",
       "1943  #usa                         49       \n",
       "2944  #impeachinghearing           47       \n",
       "4182  #qanon                       46       \n",
       "3650  #vote                        43       \n",
       "1202  #mariannewilliamson          43       \n",
       "4871  #impeachmenthearing          43       \n",
       "2770  #freedomdividend             42       \n",
       "3952  #elizabethwarren             42       \n",
       "2301  #walkaway                    41       \n",
       "100   #republicans                 41       \n",
       "442   #draintheswamp               40       \n",
       "5089  #yangmediablackout           40       \n",
       "4378  #feelthebern                 40       \n",
       "245   #voteblue                    39       \n",
       "1305  #tulsiforpresident           38       \n",
       "5146  #gop                         37       \n",
       "2438  #democrat                    37       \n",
       "4310  #teamwarren                  37       \n",
       "1428  #ukraine                     36       \n",
       "3022  #dnc                         35       \n",
       "1003  #berniebeatstrump            35       \n",
       "1212  #yanggang2020                34       \n",
       "1937  #kamalaharris                34       \n",
       "2796  #fakenews                    33       \n",
       "2005  #yangganglove                33       \n",
       "4006  #donaldtrump                 32       \n",
       "5619  #america                     32       \n",
       "3628  #demdebate                   31       \n",
       "5869  #impeachtrump                31       \n",
       "2699  #americafirst                30       \n",
       "2020  #mayorpete                   30       \n",
       "2381  #cnn                         29       \n",
       "2874  #nomiddleground              29       \n",
       "2596  #resist                      29       \n",
       "3164  #maga2020                    29       \n",
       "14    #iacaucus                    28       \n",
       "527   #ubi                         28       \n",
       "3796  #dems                        27       \n",
       "681   #nhpolitics                  27       \n",
       "3168  #fitn                        27       \n",
       "4702  #corybooker                  26       \n",
       "5613  #buttigieg                   26       \n",
       "6028  #greennewdeal                26       \n",
       "5855  #math                        26       \n",
       "356   #election                    25       \n",
       "6058  #warren                      24       \n",
       "4151  #impeachdonaldtrumpnow       24       \n",
       "3252  #sanders2020                 24       \n",
       "4447  #trump2020landslidevictory   23       \n",
       "5916  #foxnews                     23       \n",
       "1873  #iowa                        23       \n",
       "2960  #bernieblackout              22       \n",
       "3047  #impeachmentinquiry          22       \n",
       "3162  #bernie                      22       \n",
       "6042  #hunterbiden                 22       \n",
       "2991  #bidenpushupchallenge        21       \n",
       "4206  #igreport                    21       \n",
       "1528  #voteblue2020                21       \n",
       "3939  #democraticdebate            21       \n",
       "4578  #impeachandremovetrump       21       \n",
       "5047  #trump2020landslide          21       \n",
       "5986  #marianneforpresident        21       \n",
       "1909  #2020elections               21       \n",
       "3692  #buttigieg2020               20       \n",
       "410   #nomalarkey                  20       \n",
       "4633  #amyklobuchar                20       \n",
       "869   #wethepeople                 19       \n",
       "3812  #pelosi                      19       \n",
       "2076  #kamala2020                  19       \n",
       "5517  #impeachmentday              19       \n",
       "5952  #mondaythoughts              18       \n",
       "5587  #bigtruth                    18       \n",
       "3948  #resistance                  18       \n",
       "506   #china                       17       \n",
       "5949  #russia                      17       \n",
       "4245  #bidencrimefamily            17       \n",
       "3667  #democraticparty             17       \n",
       "5204  #q                           17       \n",
       "3427  #corruption                  17       \n",
       "922   #amyforamerica               17       \n",
       "3608  #m4a                         17       \n",
       "3262  #news                        17       \n",
       "1995  #thegreatawakening           17       \n",
       "3139  #trumprally                  16       \n",
       "3296  #berniesanders2020           16       \n",
       "5684  #trumpisalaughingstock       16       \n",
       "5791  #votebluenomatterwho         16       \n",
       "759   #nancypelosi                 16       \n",
       "1441  #yang                        16       \n",
       "5933  #trumpimpeachment            16       \n",
       "5272  #bluewave2020                15       \n",
       "5758  #tcot                        15       \n",
       "353   #bidencorruption             15       \n",
       "3527  #womenforyang                15       \n",
       "...             ...                ..       \n",
       "2609  #botsontheground             1        \n",
       "2627  #advertising                 1        \n",
       "2625  #trumppencemustgo            1        \n",
       "2624  #pete2020https               1        \n",
       "2623  #endcorporategreed           1        \n",
       "2622  #hindsight2020               1        \n",
       "2621  #impeachtrumpnobody          1        \n",
       "2620  #election2020maybe           1        \n",
       "2619  #moscowmuppets               1        \n",
       "2618  #joeiscomingthis             1        \n",
       "548   #charitablegiving            1        \n",
       "2616  #ifb                         1        \n",
       "2615  #wetherealpatriotsofamerica  1        \n",
       "2614  #trusttheplancross           1        \n",
       "2612  #genius                      1        \n",
       "2610  #trumppyromaniac             1        \n",
       "2585  #bernie2020red               1        \n",
       "2583  #infinity                    1        \n",
       "2632  #tee                         1        \n",
       "2547  #tulsi2020no                 1        \n",
       "2554  #makeithappen                1        \n",
       "2553  #lettulsispeak               1        \n",
       "2552  #opinionpolls                1        \n",
       "554   #warren2020neither           1        \n",
       "2550  #donkeyshit                  1        \n",
       "2549  #dcdp                        1        \n",
       "2548  #bernie2020msnbc             1        \n",
       "2545  #un                          1        \n",
       "2582  #warrensanders               1        \n",
       "2544  #moscowmitchtraitor          1        \n",
       "2543  #kamalaharrisforthepeople    1        \n",
       "2541  #resistmust                  1        \n",
       "2540  #rainbowsix                  1        \n",
       "2539  #ladiesnight                 1        \n",
       "2538  #crowdpacthat                1        \n",
       "2537  #littlemichael               1        \n",
       "2556  #maxinewatersgiven           1        \n",
       "2559  #studio10                    1        \n",
       "2560  #andrewyang2020this          1        \n",
       "553   #wintheeranow                1        \n",
       "2581  #mikehesson                  1        \n",
       "2579  #taxrevenue                  1        \n",
       "2577  #countdown                   1        \n",
       "2573  #scholars                    1        \n",
       "2572  #magacrazytrainxpress        1        \n",
       "2571  #fakeoutrageso               1        \n",
       "2570  #newwavepatriotism           1        \n",
       "2569  #onechance                   1        \n",
       "2568  #firststepact                1        \n",
       "2567  #election2020new             1        \n",
       "2566  #savedemocracy               1        \n",
       "2565  #yangonsteam                 1        \n",
       "2564  #freechelsea                 1        \n",
       "2563  #relatablememes              1        \n",
       "2562  #obamalegacy                 1        \n",
       "2631  #election2020politics        1        \n",
       "545   #dailypoll                   1        \n",
       "525   #woman                       1        \n",
       "2692  #berndowntheestablishment    1        \n",
       "2701  #baitandswitchliz            1        \n",
       "2700  #yang2020ok                  1        \n",
       "533   #politicslivewhat            1        \n",
       "2697  #abuseofcongresspower        1        \n",
       "2696  #psychologists4marianne      1        \n",
       "534   #lit                         1        \n",
       "2693  #populism                    1        \n",
       "2691  #prints                      1        \n",
       "2679  #bloombergadssuck            1        \n",
       "2689  #bettemidler                 1        \n",
       "535   #artsed                      1        \n",
       "536   #nomoreneoliberalstrue       1        \n",
       "2684  #youdontknowpete             1        \n",
       "2683  #trumpbyalandslide           1        \n",
       "2682  #dreamticket                 1        \n",
       "2681  #policiesoneverything        1        \n",
       "532   #restoredemocracyhappening   1        \n",
       "531   #usfca                       1        \n",
       "2704  #trumpism                    1        \n",
       "2705  #maltese                     1        \n",
       "526   #sweetbeadz                  1        \n",
       "2720  #merica                      1        \n",
       "2719  #belonging                   1        \n",
       "2717  #bernie2020america           1        \n",
       "2716  #creepjoebiden               1        \n",
       "2715  #19dec                       1        \n",
       "2714  #farmersfirst                1        \n",
       "2713  #goldman                     1        \n",
       "2712  #mariannewilliamson2020      1        \n",
       "2711  #downsyndrome                1        \n",
       "2710  #wisconsinforbernie          1        \n",
       "529   #gillum                      1        \n",
       "2708  #sextoy                      1        \n",
       "2707  #warren2020hell              1        \n",
       "2706  #trumpclaus                  1        \n",
       "2680  #he                          1        \n",
       "537   #corporate                   1        \n",
       "2636  #teachersforwarren           1        \n",
       "2648  #smearcampaign               1        \n",
       "543   #bernie2020hillary           1        \n",
       "2655  #neveragainisnow             1        \n",
       "2654  #therealjoebiden             1        \n",
       "2653  #metalcomedyftw              1        \n",
       "2652  #vote4yang                   1        \n",
       "2651  #kag2020andrew               1        \n",
       "544   #democratshateisrael         1        \n",
       "2647  #hufflepuff                  1        \n",
       "2677  #homeland                    1        \n",
       "2646  #twitterbuzz                 1        \n",
       "2645  #huntersgreenroom            1        \n",
       "2642  #mediabuzz                   1        \n",
       "2641  #electmorewomen              1        \n",
       "2640  #warren2020misogyny          1        \n",
       "2638  #protestants                 1        \n",
       "2637  #tom2020                     1        \n",
       "2657  #castro2020our               1        \n",
       "2658  #judiciarycommittee          1        \n",
       "2659  #pete2020really              1        \n",
       "2660  #yanggangpass                1        \n",
       "2676  #4thindustrialrevolution     1        \n",
       "2674  #nsu                         1        \n",
       "2673  #yanggangloveit              1        \n",
       "2672  #popcorntime                 1        \n",
       "2671  #yang2020here                1        \n",
       "2670  #leave                       1        \n",
       "538   #trumprallysunrise           1        \n",
       "2668  #fanniegate                  1        \n",
       "2667  #justiceforbrianterry        1        \n",
       "2666  #pentagon                    1        \n",
       "539   #oromo                       1        \n",
       "541   #mikebloombergwhat           1        \n",
       "2663  #fightthefakes               1        \n",
       "542   #biden2020agreed             1        \n",
       "2661  #uglywifebaby                1        \n",
       "6090  #warren2020agree             1        \n",
       "\n",
       "[6091 rows x 2 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tags_frequency = []\n",
    "\n",
    "for key in tagsDict:\n",
    "    tags_frequency.append([key,tagsDict[key]])\n",
    "\n",
    "\n",
    "\n",
    "# creates pandas dataframe to easily view data\n",
    "politicsSampleOrg = pd.DataFrame(data=tags_frequency, columns=['Tag', \"Frequency\"])\n",
    "\n",
    "politicsSampleOrg.sort_values(\"Frequency\", axis = 0, ascending = False, inplace = True, na_position ='last')\n",
    "\n",
    "politicsSampleOrg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "matplotlib is required for plotting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-85d4947ac942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpoliticsSampleOrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Tag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   2940\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2942\u001b[0;31m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[1;32m   2943\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36mplot_frame\u001b[0;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[1;32m   1971\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1973\u001b[0;31m                  **kwds)\n\u001b[0m\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m_plot\u001b[0;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[1;32m   1797\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m         \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0mMPLPlot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstacked\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, kind, by, subplots, sharex, sharey, use_index, figsize, grid, legend, rot, ax, fig, title, xlim, ylim, xticks, yticks, sort_columns, fontsize, secondary_y, colormap, table, layout, **kwds)\u001b[0m\n\u001b[1;32m     96\u001b[0m                  table=False, layout=None, **kwds):\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0m_raise_if_no_mpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0m_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_WARN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/plotting/_core.pyc\u001b[0m in \u001b[0;36m_raise_if_no_mpl\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# TODO(mpl_converter): remove once converter is explicit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_MPL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matplotlib is required for plotting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: matplotlib is required for plotting."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "politicsSampleOrg.plot(kind='bar', x='Tag', y='Frequency')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u2B07')\n",
    "print(u'\\uFE0F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Sound to PUT OUT FIRES ... #California Students invent a sound wave fire extinguisher https://t.co/N2NSJ7IcT4... ... @JerryBrownGov make sure the guys get their patient Fmr President @BarackObama @algore @TheEllenShow #Australia #wildfires need this help on a GIANT SCALE ..',\n",
       " u'Prescribed fires are an important way to manage our forests in order to mitigate the threat of wildfires. #wildfires #forestproud https://t.co/YqJXPEooeP',\n",
       " u\"Another great piece from @PJCavan on #CA #EnergyResilience. #blizzards and #hurricanes aren't the only weather events we need to prep for - add #wildfires to the list! FYI @TamaraMcCleary @TomRaftery @Patricia_Energy @Kevin_ODonovan \\nhttps://t.co/y32y15NCWz\",\n",
       " u'#Wildfires are common in North America today, so predicting where they will happen is of high interest. #SEFS research #scientist Susan Prichard authored a paper about a database that will help predict them: https://t.co/uOkAOKHSOA https://t.co/vleMorhWVR',\n",
       " u'INBOX: @MikeBloomberg\\'s campaign says he will travel to #California later this week \"to announce policies to curtail the region\\'s record #wildfires.\"']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows tweets without retweets\n",
    "tweets = tw.Cursor(api.search,\n",
    "                       q=new_search,\n",
    "                       lang=\"en\",\n",
    "                       tweet_mode='extended').items(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[tweet.full_text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'NancyWonderful',\n",
       "  u'',\n",
       "  u'Sound to PUT OUT FIRES ... #California Students invent a sound wave fire extinguisher https://t.co/N2NSJ7IcT4... ... @JerryBrownGov make sure the guys get their patient Fmr President @BarackObama @algore @TheEllenShow #Australia #wildfires need this help on a GIANT SCALE ..'],\n",
       " [u'CalForests',\n",
       "  u'California',\n",
       "  u'Prescribed fires are an important way to manage our forests in order to mitigate the threat of wildfires. #wildfires #forestproud https://t.co/YqJXPEooeP'],\n",
       " [u'Karin_MktgSmart',\n",
       "  u'United States',\n",
       "  u\"Another great piece from @PJCavan on #CA #EnergyResilience. #blizzards and #hurricanes aren't the only weather events we need to prep for - add #wildfires to the list! FYI @TamaraMcCleary @TomRaftery @Patricia_Energy @Kevin_ODonovan \\nhttps://t.co/y32y15NCWz\"],\n",
       " [u'UW_SEFS',\n",
       "  u'University of Washington',\n",
       "  u'#Wildfires are common in North America today, so predicting where they will happen is of high interest. #SEFS research #scientist Susan Prichard authored a paper about a database that will help predict them: https://t.co/uOkAOKHSOA https://t.co/vleMorhWVR'],\n",
       " [u'JackieTothDC',\n",
       "  u'Washington, DC',\n",
       "  u'INBOX: @MikeBloomberg\\'s campaign says he will travel to #California later this week \"to announce policies to curtail the region\\'s record #wildfires.\"']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows users that are tweeting about wildfires\n",
    "tweets = tw.Cursor(api.search, \n",
    "                           q=new_search,\n",
    "                           lang=\"en\",\n",
    "                  tweet_mode=\"extended\").items(5)\n",
    "\n",
    "users_locs = [[tweet.user.screen_name, tweet.user.location, tweet.full_text] for tweet in tweets]\n",
    "users_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NancyWonderful</td>\n",
       "      <td></td>\n",
       "      <td>Sound to PUT OUT FIRES ... #California Students invent a sound wave fire extinguisher https://t.co/N2NSJ7IcT4... ... @JerryBrownGov make sure the guys get their patient Fmr President @BarackObama @algore @TheEllenShow #Australia #wildfires need this help on a GIANT SCALE ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CalForests</td>\n",
       "      <td>California</td>\n",
       "      <td>Prescribed fires are an important way to manage our forests in order to mitigate the threat of wildfires. #wildfires #forestproud https://t.co/YqJXPEooeP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karin_MktgSmart</td>\n",
       "      <td>United States</td>\n",
       "      <td>Another great piece from @PJCavan on #CA #EnergyResilience. #blizzards and #hurricanes aren't the only weather events we need to prep for - add #wildfires to the list! FYI @TamaraMcCleary @TomRaftery @Patricia_Energy @Kevin_ODonovan \\nhttps://t.co/y32y15NCWz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UW_SEFS</td>\n",
       "      <td>University of Washington</td>\n",
       "      <td>#Wildfires are common in North America today, so predicting where they will happen is of high interest. #SEFS research #scientist Susan Prichard authored a paper about a database that will help predict them: https://t.co/uOkAOKHSOA https://t.co/vleMorhWVR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JackieTothDC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>INBOX: @MikeBloomberg's campaign says he will travel to #California later this week \"to announce policies to curtail the region's record #wildfires.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                  location  \\\n",
       "0  NancyWonderful                              \n",
       "1  CalForests       California                 \n",
       "2  Karin_MktgSmart  United States              \n",
       "3  UW_SEFS          University of Washington   \n",
       "4  JackieTothDC     Washington, DC             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                 text  \n",
       "0  Sound to PUT OUT FIRES ... #California Students invent a sound wave fire extinguisher https://t.co/N2NSJ7IcT4... ... @JerryBrownGov make sure the guys get their patient Fmr President @BarackObama @algore @TheEllenShow #Australia #wildfires need this help on a GIANT SCALE ..  \n",
       "1  Prescribed fires are an important way to manage our forests in order to mitigate the threat of wildfires. #wildfires #forestproud https://t.co/YqJXPEooeP                                                                                                                           \n",
       "2  Another great piece from @PJCavan on #CA #EnergyResilience. #blizzards and #hurricanes aren't the only weather events we need to prep for - add #wildfires to the list! FYI @TamaraMcCleary @TomRaftery @Patricia_Energy @Kevin_ODonovan \\nhttps://t.co/y32y15NCWz                  \n",
       "3  #Wildfires are common in North America today, so predicting where they will happen is of high interest. #SEFS research #scientist Susan Prichard authored a paper about a database that will help predict them: https://t.co/uOkAOKHSOA https://t.co/vleMorhWVR                     \n",
       "4  INBOX: @MikeBloomberg's campaign says he will travel to #California later this week \"to announce policies to curtail the region's record #wildfires.\"                                                                                                                               "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a pandas dataframe with the tweets\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "tweet_text = pd.DataFrame(data=users_locs, \n",
    "                    columns=['user', \"location\", \"text\"])\n",
    "\n",
    "\n",
    "\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PM Morrison has a MAJOR Conflict of Interest between his Pentecostal Church beliefs in Climate Change &amp; the action\\u2026 https://t.co/p7eZtuRZ6Y',\n",
       " u'Californie  hillbillys  - \\n \\n          Meanwhile back at the ranch - Newsome wrangles taxpayer money \\u2014 from pension\\u2026 https://t.co/OL8EyssTF9',\n",
       " u\"@CallOfDove @MrAndrewKoolaid The science is irrefutable. I'm also dying over the climate change thing. Like how on\\u2026 https://t.co/Z5smTuBPkg\",\n",
       " u'How a closed-door meeting shows farmers are waking up on climate change #SmartNews  https://t.co/3n8zfXcH9U',\n",
       " u'@GladysB @NSWRFS @DavidElliottMP @RFSCommissioner Is today the day we talk about climate change? #NSWfires #NSWbushfires']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searching for tweets with both climate and change (in that order) and printing out the first 5\n",
    "new_search = \"climate+change -filter:retweets\"\n",
    "\n",
    "tweets = tw.Cursor(api.search,\n",
    "                   q=new_search,\n",
    "                   lang=\"en\",\n",
    "                   since='2018-04-23').items(1000)\n",
    "\n",
    "all_tweets = [tweet.text for tweet in tweets]\n",
    "all_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a LARGE sample size of 100,000 tweets filtered used #politics, separated by user, location, and tweet\n",
    "\n",
    "search = '#politics -filter:retweets' # searches twitter for #politics tags and filters retweets\n",
    "\n",
    "tweets_sample = tw.Cursor(api.search,\n",
    "              q=search,\n",
    "              lang=\"en\",\n",
    "                  ).items(100000)\n",
    "\n",
    "# populates users_locs_msg with a list of users, locations, and tweets in [[user,loc], [msg]] format\n",
    "users_locs_msg = [[]] # list of users and locations\n",
    "for tweet in tweets_sample:\n",
    "    if([tweet.user.screen_name, tweet.user.location] not in users_locs_msg): # doesn't add if the user is already in the list\n",
    "        users_locs_msg.append([tweet.user.screen_name, tweet.user.location]) # appends the new user and location \n",
    "        users_locs_msg.append([tweet.text]) # appends the data for this user (always right after the user+location)\n",
    "\n",
    "        \n",
    "# changes the users_locs_msg format from [[user, loc], [msg]] to [[user, loc, msg]]\n",
    "for item in users_loc_msg: \n",
    "    if(len(item) == 2):\n",
    "        item.append(users_loc_msg[users_loc_msg.index(item)+1][0])\n",
    "    else:\n",
    "        users_loc_msg.remove(item)\n",
    "\n",
    "# creates pandas dataframe to easily view data\n",
    "politicsSample = pd.DataFrame(data=users_locs_msg, \n",
    "                    columns=['user', \"location\", \"tweet\"])\n",
    "tweet_text[:5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidentialKeywords = [\"yang2020\", \"bernie2020\", \"warren2020\", \"biden2020\", \"pete2020\", \"tulsi2020\", \"klobuchar2020\",\n",
    "                        \"steyer2020\", \"cory2020\", \"castro2020\", \"marianne2020\", \"bennet2020\", \"delaney2020\", \n",
    "                        \"bloomberg2020\", \"patrick2020\", \"trump2020\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
