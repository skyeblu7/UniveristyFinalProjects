{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card_ids:      200 200 10000000 10000199\n",
      "processor_ids: 10 10 10000000 10000009\n",
      "click_ids:     1000 1000 10000000 10000999\n",
      "vend_ids:      100 100 10000000 10000099\n",
      "category_ids:  400 400 10000000 10000399\n",
      "rating_ids:    2000 2000 10000000 10001999\n"
     ]
    }
   ],
   "source": [
    "\"Generate keys (we can't generate completely random keys or some of the relations would not work)\"\n",
    "'''\n",
    "  All 8-digit in increasing order:\n",
    "  200   card_ids\n",
    "  4     processor_ids (1 ids per 50 cards)\n",
    "  1000  click_ids     (5 ids per 1 card)\n",
    "  100   vend_ids      (1 ids per 2 cards)\n",
    "  400   category_ids (2 ids per 1 cards)\n",
    "  2000  rating_ids    (10 ids per 1 card), comes from 10 unique websites (200 ratings per site)\n",
    "'''\n",
    "\n",
    "try: card_ids = pd.read_csv('unique_random_ids/card_ids.csv')\n",
    "except:\n",
    "  card_ids = [i for i in range(10000000, 10000200)]\n",
    "  pd.DataFrame(card_ids).to_csv('unique_random_ids/card_ids.csv', index=False)\n",
    "\n",
    "try: processor_ids = pd.read_csv('unique_random_ids/processor_ids.csv')\n",
    "except:\n",
    "  processor_ids = [i for i in range(10000000, 10000010)]\n",
    "  pd.DataFrame(processor_ids).to_csv('unique_random_ids/processor_ids.csv', index=False)\n",
    "\n",
    "try: click_ids = pd.read_csv('unique_random_ids/click_ids.csv')\n",
    "except:\n",
    "  click_ids = [i for i in range(10000000, 10001000)]\n",
    "  pd.DataFrame(click_ids).to_csv('unique_random_ids/click_ids.csv', index=False)\n",
    "\n",
    "try: vend_ids = pd.read_csv('unique_random_ids/vend_ids.csv')\n",
    "except:\n",
    "  vend_ids = [i for i in range(10000000, 10000100)]\n",
    "  pd.DataFrame(vend_ids).to_csv('unique_random_ids/vend_ids.csv', index=False)\n",
    "\n",
    "try: category_ids = pd.read_csv('unique_random_ids/category_ids.csv')\n",
    "except:\n",
    "  category_ids = [i for i in range(10000000, 10000400)]\n",
    "  pd.DataFrame(category_ids).to_csv('unique_random_ids/category_ids.csv', index=False)\n",
    "\n",
    "try: rating_ids = pd.read_csv('unique_random_ids/rating_ids.csv')\n",
    "except:\n",
    "  rating_ids = [i for i in range(10000000, 10002000)]\n",
    "  pd.DataFrame(rating_ids).to_csv('unique_random_ids/rating_ids.csv', index=False)\n",
    "\n",
    "print('card_ids:     ', len(card_ids), len(pd.unique(card_ids['id'])), min(card_ids['id']), max(card_ids['id']))\n",
    "print('processor_ids:', len(processor_ids), len(pd.unique(processor_ids['id'])), min(processor_ids['id']), max(processor_ids['id']))\n",
    "print('click_ids:    ', len(click_ids), len(pd.unique(click_ids['id'])), min(click_ids['id']), max(click_ids['id']))\n",
    "print('vend_ids:     ', len(vend_ids), len(pd.unique(vend_ids['id'])), min(vend_ids['id']), max(vend_ids['id']))\n",
    "print('category_ids: ', len(category_ids), len(pd.unique(category_ids['id'])), min(category_ids['id']), max(category_ids['id']))\n",
    "print('rating_ids:   ', len(rating_ids), len(pd.unique(rating_ids['id'])), min(rating_ids['id']), max(rating_ids['id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Card_Ratings\"\n",
    "'''\n",
    "  All 8-digit in increasing order:\n",
    "  2000  rating_ids    (10 id per 1 card)\n",
    "'''\n",
    "\n",
    "rating_websites = ['card-reviews.com', 'cash-value.net', 'best-banks.com', 'only-cards.com', 'money-guide.org',\n",
    "  'top-reviews.top', 'card-guru.com', 'cardster.net', 'free-card-reviews.com', 'savememoney.com']\n",
    "\n",
    "empty = ''\n",
    "key = 'id'\n",
    "\n",
    "query = 'INSERT INTO Card_Ratings (\\n' + \\\n",
    "        '    rating_id,\\n' + \\\n",
    "        '    card_id,\\n' + \\\n",
    "        '    website_name,\\n' + \\\n",
    "        '    rating\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 2000):\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {rating_ids.loc[i, key]},\\n' + \\\n",
    "           f'        {card_ids.loc[i//10, key]},\\n' + \\\n",
    "           f'        \"{rating_websites[i//200]}\",\\n' + \\\n",
    "           f'        {rand.randint(1, 10)}\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Card_Ratings.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Categories\"\n",
    "'''\n",
    "  All 8-digit in increasing order:\n",
    "  400   category_ids  (2 ids per 1 cards)\n",
    "'''\n",
    "\n",
    "names = ['Groceries', 'Entertainment', 'Food', 'Flights', 'Investments']\n",
    "key = 'id'\n",
    "empty = ''\n",
    "\n",
    "query = 'INSERT INTO Categories (\\n' + \\\n",
    "        '    cat_id,\\n' + \\\n",
    "        '    card_id,\\n' + \\\n",
    "        '    cat_name,\\n' + \\\n",
    "        '    cat_desc,\\n' + \\\n",
    "        '    reward\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 400):\n",
    "  if i%2 == 0: tmpname = rand.choices(names, k=2)\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {category_ids.loc[i, key]},\\n' + \\\n",
    "           f'        {card_ids.loc[i//2, key]},\\n' + \\\n",
    "           f'        \"{names[i%2]}\",\\n' + \\\n",
    "           f'        \"{empty.join(rand.choices(string.ascii_lowercase, k=12))}\",\\n' + \\\n",
    "           f'        {rand.randint(0, 10)/100}\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Categories.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Click_Logs\"\n",
    "'''\n",
    "  1000  click_ids     (5 id per 1 card)\n",
    "'''\n",
    "\n",
    "def dummy_date():\n",
    "  M = rand.choice(['09', '10', '11'])\n",
    "  if M == '9': D = str(rand.randint(1, 30)).zfill(2)\n",
    "  elif M == '10': D = str(rand.randint(1, 31)).zfill(2)\n",
    "  else: D = str(rand.randint(1, 30)).zfill(2)\n",
    "  hh = str(rand.randint(0, 23)).zfill(2)\n",
    "  mm = str(rand.randint(0, 59)).zfill(2)\n",
    "  ss = str(rand.randint(0, 59)).zfill(2)\n",
    "  return f'2022-{M}-{D} {hh}:{mm}:{ss}'\n",
    "\n",
    "def get_ip():\n",
    "  a = ''\n",
    "  a += str(rand.randint(0, 255)) + '.'\n",
    "  a += str(rand.randint(0, 255)) + '.'\n",
    "  a += str(rand.randint(0, 255)) + '.'\n",
    "  a += str(rand.randint(0, 255))\n",
    "  return a\n",
    "\n",
    "key = 'id'\n",
    "empty = ''\n",
    "\n",
    "query = 'INSERT INTO Click_Logs (\\n' + \\\n",
    "        '    card_id,\\n' + \\\n",
    "        '    date_time,\\n' + \\\n",
    "        '    ip_addr\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 1000):\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {rand.choice(list(card_ids[\"id\"]))},\\n' + \\\n",
    "           f'        \"{dummy_date()}\",\\n' + \\\n",
    "           f'        \"{get_ip()}\"\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Click_Logs.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Visa' 'Mastercard' 'American Express' 'Discover']\n"
     ]
    }
   ],
   "source": [
    "names = pd.read_csv(r'ccinfo/credit_card_info.csv')\n",
    "cardname = list(names['credit card'])\n",
    "website = list(names['website'])\n",
    "image = list(names['image'])\n",
    "bank = list(names['bank'])\n",
    "proc = list(names['proc'])\n",
    "\n",
    "print(pd.unique(proc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Credit_Cards\"\n",
    "'''\n",
    "  200   card_ids\n",
    "'''\n",
    "\n",
    "key = 'id'\n",
    "empty = ''\n",
    "names = pd.read_csv(r'ccinfo/credit_card_info.csv')\n",
    "cardname = list(names['credit card'])\n",
    "website = list(names['website'])\n",
    "image = list(names['image'])\n",
    "bank = list(names['bank'])\n",
    "proc = list(names['proc'])\n",
    "\n",
    "proc_map = {'Visa': 10000000, 'American Express': 10000001, 'Mastercard': 10000002, 'Discover': 10000003}\n",
    "\n",
    "query = 'INSERT INTO Credit_Cards (\\n' + \\\n",
    "        '    card_id,\\n' + \\\n",
    "        '    card_name,\\n' + \\\n",
    "        '    processor_id,\\n' + \\\n",
    "        '    bank,\\n' + \\\n",
    "        '    annual_fee,\\n' + \\\n",
    "        '    credit_limit,\\n' + \\\n",
    "        '    signup_bonus,\\n' + \\\n",
    "        '    APR_min,\\n' + \\\n",
    "        '    APR_max,\\n' + \\\n",
    "        '    min_rec_credit,\\n' + \\\n",
    "        '    image_url,\\n' + \\\n",
    "        '    signup_link,\\n' + \\\n",
    "        '    foreign_trans_fee,\\n' + \\\n",
    "        '    reward_type\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 200):\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {card_ids.loc[i, key]},\\n' + \\\n",
    "           f'        \"{cardname[i]}\",\\n' + \\\n",
    "           f'        {proc_map[proc[i]]},\\n' + \\\n",
    "           f'        \"{bank[i]}\",\\n' + \\\n",
    "           f'        {rand.randint(0, 695)},\\n' + \\\n",
    "           f'        {rand.randint(500, 10000)},\\n' + \\\n",
    "           f'        {rand.randint(50, 2000)},\\n' + \\\n",
    "           f'        {rand.randint(1, 5)/100},\\n' + \\\n",
    "           f'        {rand.randint(5, 10)/100},\\n' + \\\n",
    "           f'        {rand.randint(300, 850)},\\n' + \\\n",
    "           f'        \"{image[i]}\",\\n' + \\\n",
    "           f'        \"{website[i]}\",\\n' + \\\n",
    "           f'        {rand.randint(5, 15)/100},\\n' + \\\n",
    "           f'        \"{rand.choice([\"c\", \"p\"])}\"\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Credit_Cards.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Payment_Processors\"\n",
    "'''\n",
    "  4     processor_ids (1 id per 50 cards)\n",
    "'''\n",
    "\n",
    "query = 'INSERT INTO Payment_Processors (\\n' + \\\n",
    "        '    processor_id,\\n' + \\\n",
    "        '    processor_name,\\n' + \\\n",
    "        '    domestic_accept,\\n' + \\\n",
    "        '    international_accept,\\n' + \\\n",
    "        '    total_cards_us,\\n' + \\\n",
    "        '    total_vol_us,\\n' + \\\n",
    "        '    num_trans,\\n' + \\\n",
    "        '    avg_proc_fee\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n' + \\\n",
    "        '    (\\n' + \\\n",
    "        '        10000000,\\n' + \\\n",
    "        '        \"Visa\",\\n' + \\\n",
    "        '        10700000,\\n' + \\\n",
    "        '        46000000,\\n' + \\\n",
    "        '        369000000,\\n' + \\\n",
    "        '        5093,\\n' + \\\n",
    "        '        255400,\\n' + \\\n",
    "        '        0.0229\\n' + \\\n",
    "        '    ),\\n' \\\n",
    "        '    (\\n' + \\\n",
    "        '        10000001,\\n' + \\\n",
    "        '        \"American Express\",\\n' + \\\n",
    "        '        10600000,\\n' + \\\n",
    "        '        44000000,\\n' + \\\n",
    "        '        56400000,\\n' + \\\n",
    "        '        1103,\\n' + \\\n",
    "        '        8300,\\n' + \\\n",
    "        '        0.02325\\n' + \\\n",
    "        '    ),\\n' + \\\n",
    "        '    (\\n' + \\\n",
    "        '        10000002,\\n' + \\\n",
    "        '        \"Mastercard\",\\n' + \\\n",
    "        '        10700000,\\n' + \\\n",
    "        '        37000000,\\n' + \\\n",
    "        '        319000000,\\n' + \\\n",
    "        '        2271,\\n' + \\\n",
    "        '        90200,\\n' + \\\n",
    "        '        0.0234\\n' + \\\n",
    "        '    ),\\n' + \\\n",
    "        '    (\\n' + \\\n",
    "        '        10000003,\\n' + \\\n",
    "        '        \"Discover\",\\n' + \\\n",
    "        '        10600000,\\n' + \\\n",
    "        '        48000000,\\n' + \\\n",
    "        '        57000000,\\n' + \\\n",
    "        '        193,\\n' + \\\n",
    "        '        2800,\\n' + \\\n",
    "        '        0.0243\\n' + \\\n",
    "        '    );'\n",
    "\n",
    "txt = open('Payment_Processors.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Preferred_Vendors\"\n",
    "'''\n",
    "  100   vend_ids      (1 id per 2 cards)\n",
    "'''\n",
    "\n",
    "key = 'id'\n",
    "empty = ''\n",
    "fnames = ['Amazon', 'Walmart', 'Target', 'United', 'Dollar Tree',\n",
    "  'Ebay', 'TJ Maxx', 'Ross', 'Burlington', 'McDonalds',\n",
    "  'Burger King', 'Panda Express', 'Home Goods', 'Home Depot', 'Facebook Marketplace',\n",
    "  'AT&T', 'American Airlines', 'Five Guys', 'Panera Bread', 'Trader Joe\\'s']\n",
    "tmpi = 0\n",
    "for pre in ['Store', 'Department', 'Supermarket', 'Restaurant']:\n",
    "  for C in string.ascii_uppercase:\n",
    "    if tmpi >= 20: tmpi = 0; break\n",
    "    tmpi += 1\n",
    "    fnames.append(f'{pre} {C}')\n",
    "ftype = ['Type 1', 'Type 2', 'Type 3', 'Type 4', 'Type 5',\n",
    "  'Type 6', 'Type 7', 'Type 8', 'Type 9', 'Type 10']\n",
    "\n",
    "query = 'INSERT INTO Preferred_Vendors (\\n' + \\\n",
    "        '    vend_id,\\n' + \\\n",
    "        '    vend_name,\\n' + \\\n",
    "        '    vend_type,\\n' + \\\n",
    "        '    vend_website\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 100):\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {vend_ids.loc[i, key]},\\n' + \\\n",
    "           f'        \"{fnames[i]}\",\\n' + \\\n",
    "           f'        \"{ftype[i//10]}\",\\n' + \\\n",
    "           f'        \"{empty.join(rand.choices(string.ascii_lowercase, k=8)) + \".com\"}\"\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Preferred_Vendors.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Generate dummy data for Offers\"\n",
    "'''\n",
    "  100   vend_ids      (1 id per 2 cards)\n",
    "'''\n",
    "\n",
    "key = 'id'\n",
    "empty = ''\n",
    "\n",
    "query = 'INSERT INTO Offers (\\n' + \\\n",
    "        '    card_id,\\n' + \\\n",
    "        '    vend_id\\n' + \\\n",
    "        ')\\n' + \\\n",
    "        'VALUES\\n'\n",
    "\n",
    "for i in range(0, 100):\n",
    "  query += f'    (\\n' + \\\n",
    "           f'        {card_ids.loc[i, key]},\\n' + \\\n",
    "           f'        {vend_ids.loc[i//2, key]}\\n' + \\\n",
    "           f'    ),\\n'\n",
    "query = query[:-2]\n",
    "query += ';'\n",
    "\n",
    "txt = open('Offers.txt', 'w')\n",
    "txt.write(query)\n",
    "txt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d48a22019fdb8b8f46f03bb3f1461cc6f7a3a87cec087e255c4ef003877589bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
